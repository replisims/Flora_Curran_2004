---
title: Replication Report
author1: Y. Andre Wang\textsuperscript{1}, 
author2: Udi Alter \textsuperscript{2}
organization1: University of Toronto Scarborough
organization2: York University
date: \today
params:
  iblue: 008080
  igray: d4dbde
documentclass: article
fontsize: 10
papersize: a4paper
output: 
  RepliSimReport:::replisim_report:
    keep_tex: TRUE
    latex_engine: xelatex
    resetStyleFiles: FALSE
header-includes: 
  - \newcommand{\iblue}{`r params$iblue`}
  - \newcommand{\igray}{`r params$igray`}
  - \usepackage{caption}
---
```{r setup, include = FALSE}
# packages
library(tinytex)
library(dplyr)
library(knitr)
library(xtable)
library(ggplot2)
library(kableExtra)

# settings
options(tinytex.verbose = TRUE)
tinytex::tlmgr_update()

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```
\captionsetup[table]{labelformat=empty}
\urlstyle{same} <!--ensure urls have the same style as the rest of the text-->

\maketitle

\section*{Abstract}

This replication report documents the replication attempt of the simulation study reported in Flora and Curran (2004). Although the original simulation code was not available to us, the article provided most of the theoretical information and instruction required to replicate the study, save for a few ambiguities (e.g., the exact tau values used to transform continuous data into ordinal data). Moreover, a recent article by Chalmers and Adkins (2020) provided the code for a partial replication of the same study using the SimDesign package in R. We recruited the code provided by Chalmers and Adkins (2020) as a base for more a complete set of simulation studies to replicate tables, graphs, and conditions reported in Flora and Curran (2004). Results from our simulation were overall consistent with the original simulation results. However, a few small differences surfaced: (1) The rates of improper solutions at small sample sizes ( _N_ = 100 and 200) using full weighted least squares estimation were higher in the replication than those in the original study; (2) the relative bias of some parameters was consistently positive in the original study but negative in the corresponding conditions in the replication; (3) the magnitude and pattern of relative bias of the factor loadings estimates differed somewhat between the original study and the replication for the two-factor models. One possible explanation for these inconsistencies might be due to the use of different software (the original study used EQS and Mplus, whereas the replication used R). A further investigation into these differences might be warranted. Full results, tables, and figures are presented below.

&nbsp;

\noindent\makebox[\textwidth]{\large Correspondence concerning this replication report should be addressed to:}

\par

\noindent\makebox[\textwidth]{\large ylawang@ucdavis.edu}

\par

\newpage

\section{Introduction}

This replication report documents the replication attempt of the simulation study [Flora & Curran (2004)](https://www.semanticscholar.org/paper/An-empirical-evaluation-of-alternative-methods-of-Flora-Curran/14e0a32ce0d079e45a54b78c5bc30735750c955f). Following the definition of @rougier_sustainable_2017-1, we understand the replication of a published study as writing and running new code based on the description provided in the original publication with the aim of obtaining the same results.

\section{Method}

\subsection{Information basis}

We drew from two sources to obtain information needed to run the replication. First, we relied on the descriptions of the simulations as reported in the original article, Flora and Curran (2004; referred to as "F&C" below). Second, we drew from the code written using the SimDesign R package by Chalmers and Adkins (2020; referred to as "C&A" below). Although F&C referred to a technical appendix that ostensibly contains example EQS code for data generation and Mplus code for model estimation (Footnote 13, p. 477; Footnote 14, p. 481), both links to the appendix were broken and we were unable to locate the appendix by visiting either author's personal websites. As part of the demonstration of the SimDesign package, C&A included code that replicates the simulation used to produce Table 6 of F&C; we drew from their code in writing our own simulation code. C&A also reported tau values used to transform continuous data to ordinal data, which were retrieved from Flora's unpublished dissertation but not reported in F&C.

\subsection{Data Generating Mechanism}

Information provided in the above mentioned sources indicated that the following simulation factors were systematically varied in generating the artificial data.

+-------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
| Simulation factor                                                 | No. levels | Levels                                                                                                                                                 |
+===================================================================+============+========================================================================================================================================================+
| *Model estimation method*                                         | 2          | Full weighted least squares (WLS), robust WLS                                                                                                          |
+-------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Number of factors*                                               | 2          | 1, 2                                                                                                                                                   |
+-------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Sample size*                                                     | 4          | 100, 200, 500, 1000                                                                                                                                    |
+-------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Number of indicators per latent factor*                          | 2          | 5, 10                                                                                                                                                  |
+-------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
| *number of categories in ordinal data*                            | 2          | 2,5                                                                                                                                                    |
+-------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Deviation from normality (skewness and kurtosis)*                | 5          | Normal, Low skewness vs. low kurtosis, Low skewness vs. moderate kurtosis, Moderate skewness vs. low kurtosis, Moderate skewness vs. moderate kurtosis |
+-------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Factor loadings*                                                 | 1          | .70                                                                                                                                                    |
+-------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Residual variances of indicators*                                | 1          | .51                                                                                                                                                    |
+-------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
| *Interfactor correlation (only for models with 2 latent factors)* | 1          | .30                                                                                                                                                    |
+-------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+

\subsubsection{Model Estimation Method}

Model estimation method was defined using the 'estimator' argument of the 'cfa' function in the 'lavaan' package, with either "WLS" (for full WLS) or "WLSMV" (for robust WLS).

\subsubsection{Number of Latent Factors}

Number of latent factors varied between the CFA models. Models 1 and 2 each had one latent factor; models 3 and 4 each had two latent factors.

\subsubsection{Sample Size}

Random samples of four different sizes were generated: 100, 200, 500, and 1,000.

\subsubsection{Number of Indicators Per Latent Factor}

Number of indicators per latent factor varied between the CFA models. In models 1 and 3, each latent factor was measured by five indicators; in models 2 and 4, each latent factor was measured by 10 indicators. Thus, the four models were:

-   Model 1: 1 latent factor, 5 indicators total
-   Model 2: 2 latent factors, 10 indicators total
-   Model 3: 1 latent factor, 10 indicators total
-   Model 4: 2 latent factors, 20 indicators total.

\subsubsection{Number of Categories in Ordinal Data}

Number of categories in ordinal data reflects the number of unique values in the ordinal observed distributions that were transformed from continuous data. In two-category conditions, the ordinal data had two unique values (defined as 0 or 1); in five-category conditions, the ordinal data had five unique values (defined as 0, 1, 2, 3, and 4).

\subsubsection{Deviation From Normality (Skewness and Kurtosis)}

Deviation from normality was defined as a combination of non-zero skewness and non-zero kurtosis. The conditions are as follows:

| Condition                                 | Skewness | Kurtosis |
|-------------------------------------------|----------|----------|
| *Normal*                                  | 0        | 0        |
| *Low skewness vs. low kurtosis*           | 0.75     | 1.75     |
| *Low skewness vs. moderate kurtosis*      | 0.75     | 3.75     |
| *Moderate skewness vs. low kurtosis*      | 1.25     | 1.75     |
| *Moderate skewness vs. moderate kurtosis* | 1.25     | 3.75     |

\subsubsection{Fixed Values}

Factor loadings represent the standardized regression coefficients of the latent response variables (i.e., the continuous variables pre-transformation) on the latent factors, and all factor loadings were set to .70. All latent responses variables were standardized to have means of zero and unit variances; thus, the residual variance of each was set to 1 - .7\^2 = .51. The latent factors were also set to have unit variances. For models with two latent factors (Models 2 and 4), the interfactor correlation was set to 0.30. Each condition of the simulations was iterated 500 times.

\FloatBarrier

\subsection{Compared Methods}

The study compares two methods of fitting confirmatory factor analysis (CFA) models to estimate polychoric correlations among ordinal variables (e.g., Likert-type items) across different conditions encountered by applied researchers. The statistical performance of the two methods, fully weighted least squares (WLS) and robust WLS, was compared across various levels of nonnormality of the underlying continuous latent distribution.

\subsubsection{Full WLS}

The WLS approach was developed for estimating a weighted matrix based on the asymptotic variances and covariances of polychoric correlations that can be used in conjunction with a matrix of polychoric correlations in the estimation of SEM models (e.g., Browne, 1982, 1984; Jöreskog, 1994; B. Muthén, 1984; B. O. Muthén & Satorra, 1995). WLS applies the fitting function:

$$F_{WLS} = [s- \sigma(\theta)]^{\prime}W^{-1}[s - \sigma(\theta)]$$ In our replication, we implemented full WLS with 'estimator = "WLS"' argument of the 'cfa' function in the 'lavaan' package.

\subsubsection{Robust WLS}

The robust WLS approach was developed by B. Muthén et al. (1997) to address the problems faced when using WLS with small to medium samples. Built on the works of Satorra and colleagues (Chou et al., 1991; Satorra, 1992; Satorra & Bentler, 1990), the robust WLS approach obtains parameter estimates by substituting a diagonal matrix, V, for W in the full WLS approach. The diagonal matrix contains the asymptotic variances of the thresholds and polychoric correlation estimates. Calculation of this matrix involves the full weight matrix W (as in the above equation); however, it does not need to be inverted. A robust goodness-of-fit test can be calculated with a mean- and variance-adjusted chi-square test statistic, which similarly involves the full weight matrix W but avoids inversion.

\subsection{Performance measures}

The primary performance measure was the mean relative bias (RB), defined as:

$$RB = (\frac{\hat{\theta} - \theta}{\theta})*100 $$

Where $\hat{\theta}$ is the estimated statistic from a given replication, and $\theta$ is the corresponding population parameter. Following F&C, we calculated the mean RB across replications within a given condition. We focused on three estimated statistics: chi-square test statistics, polychoric correlations, and factor loadings. For the $\chi^{2}$ test statistics from full WLS estimation, the RB was calculated with respect to the degree of freedom of each model. For the factor loadings and the polychoric correlations, the RB was calculated with $\theta$ as the population value, and $\hat{\theta}$ as the pooled mean of the statistic:

$$ Pooled\ Mean = P^{-1} \displaystyle \sum_{i=1}^P \bar{\hat{\lambda_i}} $$

In addition, the square root of the mean of the statistic variances was calculated to quantify the variance of the mean statistic estimates: $$Pooled\ SD = \sqrt{P^{-1}\sum_{i=1}^P VAR(\hat{\lambda_i})}$$ Note that although F&C further considered the RB of standard error estimation (p. 474), we did not examine it in our replication because F&C did not fully report the results of that metric, thus preventing us from being able to directly compare our results to theirs (the link to the technical appendix that would include results on that metric was broken). In addition to RB, rates of improper solutions were assessed as a secondary performance measure. An improper solution was defined as "a nonconverged solution or a solution that converged but resulted in one or more out-of-bound parameters (e.g., Heywood cases)" (p. 473, F&C).


\subsection{Technical implementation}

While the original simulation study was carried out in EQS (for data generation) and Mplus (for data analysis), our replication was implemented using the R programming environment (details regarding software versions can be obtained from the section Reproducibility Information). The corresponding R code can be obtained from [GitHub.](https://github.com/replisims/Flora_Curran_2004)

The following table provides an overview of replicator degrees of freedom, i.e. decisions that had to be made by the replicators because of insufficient or contradicting information. Issues were resolved by discussion among the replicators. Decisions were based on what the replicators perceived to be the most likely implementation with likeliness estimated by common practice and/or guideline recommendations. Wherever feasible multiple interpretations were implemented.

+-------------------------------------------------------------------+----------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
| Issue                                                             | Replicator decision                                                  | Justification                                                                                                                           |
+===================================================================+======================================================================+=========================================================================================================================================+
| Lack of access to the original software environment               | Conducted the replication in R                                       | Success of the replication should not depend on the software used                                                                       |
+-------------------------------------------------------------------+----------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|                                                                   |                                                                      |                                                                                                                                         |
+-------------------------------------------------------------------+----------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
| Tau values not reported or misreported in the original article    | Followed the tau values reported in Chalmers and Adkins (2020)       | Tau values for transforming continuous data into two-category ordinal data were not explicitly reported; tau values for five-category ordinal data produced distributions inconsistent with the original article |
+-------------------------------------------------------------------+----------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|                                                                   |                                                                      |                                                                                                                                         |
+-------------------------------------------------------------------+----------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
| Some results were not readily available in the primary replication | Ran 2 additional simulation studies for Tables 2 and 3, respectively | Results from Tables 2 and 3 were not directly available from the replication of the primary simulation study                            |
+-------------------------------------------------------------------+----------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|                                                                   |                                                                      |                                                                                                                                         |
+-------------------------------------------------------------------+----------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
| Too many models fail to converge in some conditions               | Decided to omit those conditions from the replication                | Could not obtain parameter estimates to assess estimator performance because of nonconverging models; consistent with decision in C&A   |
+-------------------------------------------------------------------+----------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+

\subsection{Lack of Access to the Original Software Environment}
The original simulation studies reported in F&C used EQS (Version 5.7b; Bentler, 1995) for data generation and Mplus (Version 2.01; L. K. Muthén & Muthén, 1998) for data analysis. Because the script for these software environments was unavailable to us (see Section 2.1 above), and because we did not have access to EQS, a proprietary software, we decided to implement both data generation and data analysis in R (see Appendix for details). Specifically, we relied on two core packages, lavaan and SimDesign, for the bulk of our replication efforts.

\subsection{Tau Values not Reported or Misreported in the Original Article}
Tau values are thresholds used for transforming continuous data into ordinal data. F&C generated ordinal data from continuous data with various degrees of nonnormality; however, the tau values used to do so were not directly reported in the original article. For two-category ordinal data, the tau value was not reported. Although one can reasonably assume that the tau value for transforming normal, standardized distribution into ordinal data is 0 (the mean of such a distribution), it is unclear whether the tau value for nonnormal distribution should still be 0 or not. Based on C&A, we chose tau = 0 for all transformations from continuous data to two-category ordinal data. For five-category ordinal data, F&C referred to tau values reported in Muthén and Kaplan (1985) in Footnote 9, noting that "[t]his same threshold set was also applied to each nonnormal y\*distribution." Yet C&A suggested that this was not accurate: For the moderate skewness vs. low kurtosis condition (skewness = 1.25, kurtosis = 1.75), the first threshold was not -1.645 (p. 176; Muthén & Kaplan, 1985), but -1.125. C&A noted that this modification was included in Flora's (2002) unpublished dissertation, which we do not have access to. We confirmed that this modification was likely made by F&C: Using the modified threshold gave us results that closely matched those of F&C for that condition in Table 1, but using the threshold reported in Muthén and Kaplan (1985) did not. Therefore, we decided to use the modified tau values as reported by C&A in our replications. (The tau values are presumably reported in the original script; as we note in Section 2.1, however, we did not have access to the original script and thus were unable to confirm them.)

\subsection{Some Results Were not Readily Available in the Primary Replication}
F&C reported one primary simulation study, the results from which were reported in Tables 2-11 (results reported in Table 1 was from a separate simulation study, for which we conducted a separate replication). We however found that the results reflecting those reported in Tables 2 and 3 were not readily available in our primary replication conducted in SimDesign. In Table 2, F&C examined the accuracy of polychoric correlation estimates by generating bivariate data for each of two population correlation values, before estimating CFA models on those polychoric correlations. In contrast, because our primary replication in SimDesign generated data directly from the CFA models, the polychoric correlation estimates were not directly available in the output. Therefore, we conducted a separate replication to examine the accuracy of the polychoric correlation estimates. In Table 3, F&C examined the rate of improper solutions at small sample sizes ( _N_ = 100 and _N_ = 200). Improper solutions were defined as model solutions that either do not converge or contain out-of-bound estimates (i.e., Heywood cases). The safeguarding features of SimDesign prevented us from running conditions in which a high rate of nonconvergence occurred. Therefore, we conducted a separate replication to examine the rate of improper solutions at small sample sizes without using SimDesign.\subsection{Too Many Models Fail to Converge in Some Conditions}
F&C reported results for Model 4 at _N_ = 200  using full WLS in Tables 7 and 11. In our replication, however, we found that the rate of nonconvergence for these conditions were too high (see Table 3 of our replication below). Because we could not obtain model fit statistics or parameter estimates from nonconverging models, we excluded these conditions from our replication results reported below.
\clearpage
```{=tex}
\FloatBarrier
\section{Results}
```

```{r}
# Read primary simulation replication data (Tables 4-11 and Figure 6)
res <- readRDS("FloraCurran2004_210826.rds")
# Format data
res %>% 
  # Label skewness (s), kurtosis (k), Type I error rate; calculate RB for lambda
  mutate(s = sapply(res$skewness_kurtosis, function(x) x[1]),
         k = sapply(res$skewness_kurtosis, function(x) x[2]),
         "% reject" = edr_05 * 100) %>%
  # Keep only 5-category ordinal data for constructing tables, per F&C
  filter(categories == 5) -> res_dat

# Read additional simulation replication data (Tables 1-3)
dat_tab1 <- readRDS("FloraCurran2004_Table1.rds")
dat_tab2 <- readRDS("FloraCurran2004_Table2.rds")
dat_tab3 <- readRDS("FloraCurran2004_Table3.rds")

## TABLE 1 (Skewness and Kurtosis of Univariate Latent Response, y* Distributions, and Five-Category Ordinal,y Distributions)

dat_tab1$skewness_ord <- round(dat_tab1$skewness_ord, 2)
dat_tab1$kurtosis_ord <- round(dat_tab1$kurtosis_ord, 2)
condition <- c("Normal", "Low skewness vs. low kurtosis", "Low skewness vs. moderate kurtosis", "Moderate skewness vs. low kurtosis", "Moderate skewness vs. moderate kurtosis 1")
tab1 <- cbind(condition, dat_tab1)

knitr::kable(tab1, col.names = c("Condition", "y* Skewness", "y* Kurtosis", "y Skewness", "y Kurtosis"),format="latex", booktabs=TRUE, caption = "TABLE 1: Skewness and Kurtosis of Univariate Latent Response, y* Distributions, and Five-Category Ordinal,y Distributions") %>% kable_styling(latex_options="scale_down")


## TABLE 2 (Means, Standard Deviations, and Relative Bias of Polychoric Correlation Estimates)
tab2_rho1 <- dat_tab2 %>% 
  mutate(s = sapply(skewness_kurtosis, function(x) x[1]),
         k = sapply(skewness_kurtosis, function(x) x[2])) %>%
  arrange(categories, sample.size) %>%
  filter(rho == .147) %>%
  select(sample.size, s, k, categories, rho, rho_mean, rho_sd, rho_RB)

tab2_rho2 <- dat_tab2 %>% 
  mutate(s = sapply(skewness_kurtosis, function(x) x[1]),
         k = sapply(skewness_kurtosis, function(x) x[2])) %>%
  arrange(categories, sample.size) %>%
  filter(rho == .49) %>%
  select(sample.size, s, k, categories, rho, rho_mean, rho_sd, rho_RB)

# rho = .147 for 2 categories and 5 categories

tab21 <- tab2_rho1[1:20,] 
tab22 <- tab2_rho1[21:40,]

tab2.147 <- full_join(tab21, tab22, by = c("sample.size", "s", "k", "rho"))

tab2.147 <- tab2.147 %>% select(-rho)

colnames(tab2.147) <- c("N", "s", "k", "2 cat", "M(rho=.147/2cat)", "SD(rho=.147/2cat)", "RB(rho=.147/2cat)", "5 cat","M(rho=.147/5cat)", "SD(rho=.147/5cat)", "RB(rho=.147/5cat)")


# rho = .49 for 2 categories and 5 categories
tab2_rho2 <- dat_tab2 %>% 
  mutate(s = sapply(skewness_kurtosis, function(x) x[1]),
         k = sapply(skewness_kurtosis, function(x) x[2])) %>%
  arrange(categories, sample.size) %>%
  filter(rho == .49) %>%
  select(sample.size, s, k, categories, rho, rho_mean, rho_sd, rho_RB)


tab23 <- tab2_rho2[1:20,] 
tab24 <- tab2_rho2[21:40,]

tab2.49 <- full_join(tab23, tab24, by = c("sample.size", "s", "k", "rho"))

tab2.49 <- tab2.49 %>% select(-rho)

colnames(tab2.49) <- c("N", "s", "k", "2 cat", "M(rho=.49/2cat)", "SD(rho=.49/2cat)", "RB(rho=.49/2cat)", "5 cat","M(rho=.49/5cat)", "SD(rho=.49/5cat)", "RB(rho=.49/5cat)")


tab2 <- full_join(tab2.147, tab2.49, by=c("N", "s", "k"))

tab2 <- tab2 %>% select(- "2 cat.x")
tab2 <- tab2 %>% select(- "5 cat.x")
tab2 <- tab2 %>% select(- "2 cat.y")
tab2 <- tab2 %>% select(- "5 cat.y")
knitr::kable(tab2, format="latex", booktabs=TRUE,caption = "TABLE 2: Means, Standard Deviations, and Relative Bias of Polychoric Correlation Estimates", digits=2) %>% kable_styling(latex_options="scale_down")

## TABLE 3 (Rates of Improper Solutions Obtained With Full WLS Estimation)
# ip = rate of improper solutions
# nc = rate of nonconverged solutions

# 2 categories model
tab31 <- dat_tab3[[1]]
colnames(tab31) <- c("N", "s", "k","2cat:imp.mod1", "2cat:nc.mod1",
                                     "2cat:imp.mod2", "2cat:nc.mod2",
                                     "2cat:imp.mod3", "2cat:nc.mod3",
                                     "2cat:imp.mod4", "2cat:nc.mod4")

# 5 categories model
tab32 <- dat_tab3[[2]]
colnames(tab32) <- c("N", "s", "k","5cat:imp.mod1", "5cat:nc.mod1",
                     "5cat:imp.mod2", "5cat:nc.mod2",
                     "5cat:imp.mod3", "5cat:nc.mod3",
                     "5cat:imp.mod4", "5cat:nc.mod4")

tab3 <- full_join(tab31, tab32, by=c("N", "s", "k"))

knitr::kable(tab3, format="latex", booktabs=TRUE, caption = "TABLE 3: Rates of Improper Solutions Obtained With Full WLS Estimation") %>%
  footnote("imp = rate of improper solutions.")%>%
  kable_styling(latex_options="scale_down")

## TABLE 4 (Chi-Square Test Statistics for Model 1 [Five Indicators, One Factor])
res_dat %>%
  filter(indicators == 5, factors == 1, estimator == 'WLS') %>%
  select(N, s, k, M_X2, SD_X2, RB_X2, "% reject") %>%
    rename("WLS M" = 'M_X2', "WLS SD" = 'SD_X2', "WLS RB" = 'RB_X2',"WLS % reject"="% reject" )  -> WLS_4
res_dat %>%
  filter(indicators == 5, factors == 1, estimator == 'WLSMV') %>%
  select(N, s, k, RB_X2, "% reject") %>%
      rename("Robust WLS RB" = 'RB_X2',"Robust WLS % reject"="% reject" ) -> WLSMV_4
full_join(WLS_4, WLSMV_4, by = c("N", "s", "k")) %>%
  arrange(N, s, k)  -> tab4

knitr::kable(tab4, align = 'c', format="latex", booktabs=TRUE, caption = "TABLE 4: Chi-Square Test Statistics for Model 1 (Five Indicators, One Factor)",digits=2)%>% kable_styling(latex_options="scale_down")

#Note: imp = rate of improper solutions.
## TABLE 5 (Chi-Square Test Statistics for Model 2 [10 Indicators, One Factor])
res_dat %>%
  filter(indicators == 10, factors == 1, estimator == 'WLS') %>%
  select(N, s, k, M_X2, SD_X2, RB_X2, "% reject") %>%
rename("WLS M" = 'M_X2', "WLS SD" = 'SD_X2', "WLS RB" = 'RB_X2',"WLS % reject"="% reject" ) -> WLS_5

res_dat %>%
  filter(indicators == 10, factors == 1, estimator == 'WLSMV') %>%
  select(N, s, k, RB_X2, "% reject") %>%
      rename("Robust WLS RB" = 'RB_X2',"Robust WLS % reject"="% reject" ) -> WLSMV_5

full_join(WLS_5, WLSMV_5, by = c("N", "s", "k")) %>%
  arrange(N, s, k) -> tab5
knitr::kable(tab5, align = 'c', format="latex", booktabs=TRUE, caption = "TABLE 5: Chi-Square Test Statistics for Model 2 (10 Indicators, One Factor)", digits=2)%>% kable_styling(latex_options="scale_down")

## TABLE 6 (Chi-Square Test Statistics for Model 3 [10 Indicators, Two Correlated Factors])
res_dat %>%
  filter(indicators == 5, factors == 2, estimator == 'WLS') %>%
  select(N, s, k, M_X2, SD_X2, RB_X2, "% reject") %>% 
rename("WLS M" = 'M_X2', "WLS SD" = 'SD_X2', "WLS RB" = 'RB_X2',"WLS % reject"="% reject" ) -> WLS_6

res_dat %>%
  filter(indicators == 5, factors == 2, estimator == 'WLSMV') %>%
  select(N, s, k, RB_X2, "% reject") %>%
rename("Robust WLS RB" = 'RB_X2',"Robust WLS % reject"="% reject" ) -> WLSMV_6

full_join(WLS_6, WLSMV_6, by = c("N", "s", "k")) %>%
  arrange(N, s, k) -> tab6

knitr::kable(tab6, align = 'c', format="latex", booktabs=TRUE, caption = "TABLE 6: Chi-Square Test Statistics for Model 3 (10 Indicators, Two Correlated Factors)", digits=2)%>% kable_styling(latex_options="scale_down")

# FIGURE 6: Generate summary data for Figure 6 in F&C

res_dat %>%
  filter(indicators == 5) %>%
  mutate(TypeI = edr_05 * 100,
         est_fact = factor(estimator):factor(factors)) %>%
  group_by(N, est_fact) %>%
  summarise(mean_TypeI = mean(TypeI)) -> fig6dat
labels <- c("Model 1 (full WLS estimation)", "Model 3 (full WLS estimation)",
            "Model 1 (robust WLS estimation)", "Model 3 (robust WLS estimation)")

# Reproduce Figure 6 using the ggplot2 package
p <- ggplot(fig6dat,
       aes(x = factor(N), y = mean_TypeI, linetype = est_fact,
            shape = est_fact, group = est_fact)) +
  geom_line() + geom_point(size = 4) +
  geom_hline(yintercept = 5, colour = 'red', linetype = 'dashed') +
  xlab("Sample Size") + ylab("Type I Error Rate") +
  scale_linetype_discrete(labels = labels) +
  scale_shape_discrete(labels = labels) +
  ylim(0, 80) + theme_bw() +
  theme(legend.title= element_blank(),
        legend.position = c(.8, .7),
        axis.line = element_line(colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank()
  )

gridExtra::grid.arrange(p, bottom="FIGURE 1: Generate summary data for Figure 6 in F&C")

## TABLE 7: Chi-Square Test Statistics for Model 4 (20 Indicators, Two Correlated Factors)
res_dat %>%
  filter(indicators == 10, factors == 2, estimator == 'WLS') %>%
  select(N, s, k, M_X2, SD_X2, RB_X2, "% reject") %>% 
rename("WLS M" = 'M_X2', "WLS SD" = 'SD_X2', "WLS RB" = 'RB_X2',"WLS % reject"="% reject" ) -> WLS_7

res_dat %>%
  filter(indicators == 10, factors == 2, estimator == 'WLSMV') %>%
  select(N, s, k, RB_X2, "% reject") %>%
rename("Robust WLS RB" = 'RB_X2',"Robust WLS % reject"="% reject" ) -> WLSMV_7

full_join(WLS_7, WLSMV_7, by = c("N", "s", "k"), suffix= c('', '.DWLS')) %>%
  arrange(N, s, k) -> tab7
knitr::kable(tab7, align = 'c', format="latex", booktabs=TRUE, caption = "TABLE 7: Chi-Square Test Statistics for Model 4 (20 Indicators, Two Correlated Factors)", digits=2)%>% kable_styling(latex_options="scale_down")

# F&B reported results for N = 200 but they are not part of the replication here
# due to nonconvergence (i.e., no model converged in our replications)
# See replication of Table 3 for details on improper solutions

## TABLE 8 (Mean Factor Loadings for Model 1 [Five Indicators, One Factor])
res_dat %>%
  filter(indicators == 5, factors == 1, estimator == 'WLS') %>%
  select(N, s, k, M_lambda, SD_lambda, RB_lambda) %>%
rename("WLS pooled M" = 'M_lambda', "WLS pooled SD" = 'SD_lambda', "WLS RB" = 'RB_lambda')-> WLS_8

res_dat %>%
  filter(indicators == 5, factors == 1, estimator == 'WLSMV') %>%
  select(N, s, k, M_lambda, SD_lambda, RB_lambda) %>% 
rename("Robust WLS pooled M" = 'M_lambda', "Robust WLS pooled SD" = 'SD_lambda', "Robust WLS RB" = 'RB_lambda')-> WLSMV_8

full_join(WLS_8, WLSMV_8, by = c("N", "s", "k")) %>%
  arrange(N, s, k) -> tab8

knitr::kable(tab8, align = 'c', format="latex", booktabs=TRUE, caption = "TABLE 8: Mean Factor Loadings for Model 1 (Five Indicators, One Factor)", digits=2)%>% kable_styling(latex_options="scale_down")

## TABLE 9: Mean Factor Loadings for Model 2 (10 Indicators, One Factor)
res_dat %>%
  filter(indicators == 10, factors == 1, estimator == 'WLS') %>%
  select(N, s, k, M_lambda, SD_lambda, RB_lambda) %>%
rename("WLS pooled M" = 'M_lambda', "WLS pooled SD" = 'SD_lambda', "WLS RB" = 'RB_lambda') -> WLS_9

res_dat %>%
  filter(indicators == 10, factors == 1, estimator == 'WLSMV') %>%
  select(N, s, k, M_lambda, SD_lambda, RB_lambda) %>% 
rename("Robust WLS pooled M" = 'M_lambda', "Robust WLS pooled SD" = 'SD_lambda', "Robust WLS RB" = 'RB_lambda') -> WLSMV_9

full_join(WLS_9, WLSMV_9, by = c("N", "s", "k")) %>%
  arrange(N, s, k) -> tab9

knitr::kable(tab9, align = 'c', format="latex", booktabs=TRUE, caption = "TABLE 9: Mean Factor Loadings for Model 2 (10 Indicators, One Factor)", digits=2)%>% kable_styling(latex_options="scale_down")


## TABLE 10 (Mean Parameter Estimates for Model 3 [10 Indicators, Two Factors])
res_dat %>%
  filter(indicators == 5, factors == 2, estimator == 'WLS') %>%
  select(N, s, k, M_lambda, SD_lambda, RB_lambda, M_phi21, SD_phi21, RB_phi21)%>% 
rename("WLS lambda M" = 'M_lambda', "WLS lambda SD" = 'SD_lambda', "WLS lambda RB" = 'RB_lambda',
       "WLS phi21 M"='M_phi21',"WLS phi21 SD"= 'SD_phi21', 'WLS phi21 RB'='RB_phi21' )-> WLS_10
res_dat %>%
  filter(indicators == 5, factors == 2, estimator == 'WLSMV') %>%
  select(N, s, k, M_lambda, SD_lambda, RB_lambda,
         M_phi21, SD_phi21, RB_phi21) %>%
rename("Robust lambda M" = 'M_lambda', "Robust lambda SD" = 'SD_lambda', "Robust lambda RB" = 'RB_lambda',
       "Robust phi21 M"='M_phi21',"Robust phi21 SD"= 'SD_phi21', 'Robust phi21 RB'='RB_phi21' )-> WLSMV_10

full_join(WLS_10, WLSMV_10, by = c("N", "s", "k")) %>%
  arrange(N, s, k) -> tab10

knitr::kable(tab10, format="latex", booktabs=TRUE, caption = "TABLE 10: Mean Parameter Estimates for Model 3 (10 Indicators, Two Factors)", digits=2) %>% 
  kable_styling(latex_options="scale_down")

## TABLE 11 (Mean Parameter Estimates for Model 4 [20 Indicators, Two Factors])
res_dat %>%
  filter(indicators == 10, factors == 2, estimator == 'WLS') %>%
  select(N, s, k, M_lambda, SD_lambda, RB_lambda,
         M_phi21, SD_phi21, RB_phi21) %>%
  rename("WLS lambda M" = 'M_lambda', "WLS lambda SD" = 'SD_lambda', "WLS lambda RB" = 'RB_lambda',
       "WLS phi21 M"='M_phi21',"WLS phi21 SD"= 'SD_phi21', 'WLS phi21 RB'='RB_phi21' ) -> WLS_11

res_dat %>%
  filter(indicators == 10, factors == 2, estimator == 'WLSMV') %>%
  select(N, s, k, M_lambda, SD_lambda, RB_lambda,
         M_phi21, SD_phi21, RB_phi21) %>% 
rename("Robust lambda M" = 'M_lambda', "Robust lambda SD" = 'SD_lambda', "Robust lambda RB" = 'RB_lambda',
       "Robust phi21 M"='M_phi21',"Robust phi21 SD"= 'SD_phi21', 'Robust phi21 RB'='RB_phi21' ) -> WLSMV_11

full_join(WLS_11, WLSMV_11, by = c("N", "s", "k")) %>%
  arrange(N, s, k) -> tab11

knitr::kable(tab11, format="latex", booktabs=TRUE, caption = "TABLE 11: Mean Parameter Estimates for Model 4 (20 Indicators, Two Factors)", digits=2) %>% 
  kable_styling(latex_options="scale_down")
```

```{=tex}
\FloatBarrier
\section{Discussion}
```
\subsection{Replicability}
The replication process was mostly straightforward. F&C had provided almost all of the information required to execute our replication. C&A provided further insight into replicating the original simulation in R using the SimDesign package, including sample R code that became the base script of our primary replication study. Together, these two sources were informative in conducting our replication. The key challenges were: (1) The links to the technical appendix and the code in F&C were broken, so we could not directly compare our simulation code to theirs; (2) some information, such as tau values used to transform continuous data to categorical data, was not directly reported in the paper; and (3) in part because we used a different software environment, we decided to conduct additional simulation studies to fully assess the original results reported in F&C.
\subsection{Replicator degrees of freedom}
Our replication could benefit from additional information that was not available to us at the time of replication, including the exact tau values used to transform continuous data into categorical ordinal data. As discussed above, they did not report the tau value used for the two-category conditions, and although they referred to the source of tau values used for the five-category conditions in a Footnote, they did not disclose whether those values were used in all of those conditions. Based on C&A and our own replication attempt, we believe that the first threshold in the conditions with moderate skewness and low kurtosis was altered. In addition, access to the original appendix and code would have helped reduce our replicator degrees of freedom. To be fair to the authors, however, sharing code via permalink was uncommon and few viable solutions were available when the paper was published. We do not believe that the replicator degrees of freedom are so intensive that they should influence the results.
\subsection{Equivalence of results}
Results from our simulation were overall consistent with the original simulation results, and we would draw similar conclusions as the original authors. First, we almost exactly replicated the skewness and kurtosis of the five-category ordinal distributions (Table 1 of F&C), and the means, SDs, and RB of polychoric correlation estimates were comparable to the original estimates as well (Table 2 of F&C). Next, we observed the same pattern of chi-square test statistics across all four models (i.e., means, SDs, RB, and Type I error rates; Tables 4--7 of F&C), except for one set of conditions (N = 200 for Model 4 with full WLS; see discussion below). The orders of magnitude were comparable, and the trends were in the same direction. On parameter estimates, we also observed largely similar patterns of factor loading estimates across full WLS and robust WLS for Models 1 and 2 (with one factor), and the impact of sample size, skewness and kurtosis on those estimates followed the same pattern as the original simulation study as well; likewise, results on the interfactor correlations for Models 3 and 4 were also highly consistent with those in F&C.

We did observe three sets of notable differences. First, the rates of improper solutions obtained with full WLS at small sample sizes (N = 100 or 200) in our replication were often higher than those in the original study, largely due to nonconvergence (Table 3). Although our rates of improper solutions matched those in F&C for Models 1--3 with two-category data, we observed 100% nonconvergence for Model 4 with two-category data; in contrast, F&C found 65--90% of the solutions were improper, with 5--35% due to nonconvergence. In addition, although F&C found minimal rates of improper solutions (0--2%) across levels of nonnormality for Models 1--3 with five-category data, we found that increasing levels of skewness and kurtosis had major impact on rates of improper solutions for those models. Specifically, as skewness and kurtosis increased, so did the rate of improper solutions, reaching 12.6%, 47.6%, and 18.4% for Models 1--3, respectively. Lastly, for Model 4 with five-category data, F&C found 100% nonconvergence at _N_= 100 and around 20--30% improper solutions (with 0% nonconvergence) at _N_= 200; in contrast, we found 100% nonconvergence at both_N_= 100 and _N_= 200. Because of the nonconvergence at _N_= 200 for Model 4 with five-category data using full WLS, we could not assess the performance of full WLS in those conditions (see our replicated Tables 7 and 11).

Second, in Models 3 and 4 (both with two correlated factors) with five-category data, the factor loading estimates consistently showed negative RB (i.e., the estimates were lower than the population value of .7), whereas those in F&C consistently showed positive RB.

Third, the magnitude and pattern of RB on parameter estimates also differed somewhat from F&C, particularly on the factor loading estimates for Models 3 and 4 (i.e., models with two factors). Whereas F&C found that RB of parameter estimates increased with increasing model size, particularly with full WLS estimation, our replication found only sporadic evidence for this pattern (RB of interfactor correlation estimates was greater in the bigger Model 4 vs. the smaller Model 3; RB of factor loadings using robust WLS estimation was greater in Models 3 and 4 vs. Models 1 and 2; however, RB of factor loadings using full WLS estimation was mostly unrelated to model size). In addition, F&C noted that RB in parameter estimates was notably smaller with robust vs. full WLS; in our replication, this was not the case for factor loading estimates in Models 3 and 4 (if anything, the robust WLS estimation performed worse, at trivial to moderate levels of RB, rather than at trivial levels of RB as F&C observed).

It is unclear to us why these discrepancies occurred. One possible explanation for these discrepancies is the different software environments used for data generation analysis and data analysis. A further investigation into these discrepancies might be warranted. We do not believe these discrepancies crucially undermine the conclusions of F&C. Some discrepancies, assuming they reflect substantive differences, might be worth keeping in mind, especially for those using R and lavaan for data analysis (e.g., in two-factor CFA, full WLS might perform worse at smaller sample sizes than F&C suggested, and factor loadings might be underestimated rather than overestimated).

Finally, it is worth noting that the current replication does not address the design of the simulation study itself: That is, how the original authors operationalized the research question. For example, a different team of researchers might choose different models to test the performance of the two estimation methods, set different levels of factor loadings (or examine how the strength of factor loadings might affect the performance of the methods), or examine different mechanisms of generating nonnormal data (for recent critiques of the Vale-Maurelli method of generating nonnormal data, see Olvera Astivia & Zumbo, 2015; Foldnes & Grønneberg, 2019; see Foldnes & Grønneberg, 2021, for a simulation study on the performance of estimators using Piecewise Linear Transforms, a new nonnormal data generation method).
\section*{References}
- Chalmers, R. Philip, Adkins, Mark C. (2020). Writing Effective and Reliable Monte Carlo Simulations with the SimDesign Package, _The Quantitative Methods for Psychology_, _16_(4), 248-280. https://doi.org/10.20982/tqmp.16.4.p248
- Chalmers, R. P. (2020). SimDesign: Structure for Organizing Monte Carlo Simulation Designs. R package version 2.1. Retrieved from https://CRAN.R-project.org/
package=SimDesign
- Flora, D. B., & Curran, P. J. (2004). An empirical evaluation of alternative methods of estimation for confirmatory factor analysis with ordinal data. _Psychological Methods_, _9_(4), 466–491. https://doi.org/10.1037/1082-989X.9.4.466
- Foldnes, N., & Grønneberg, S. (2019). On Identification and Non-normal Simulation in Ordinal Covariance and Item Response Models. _Psychometrika_, _84_(4), 1000–1017. https://doi.org/10.1007/s11336-019-09688-z
- Foldnes, N., & Grønneberg, S. (2021). The sensitivity of structural equation modeling with ordinal data to underlying non-normality and observed distributional forms. _Psychological Methods_. Advance online publication. https://doi.org/10.1037/met0000385
- Olvera Astivia, O. L., & Zumbo, B. D. (2015). A Cautionary Note on the Use of the Vale and Maurelli Method to Generate Multivariate, Nonnormal Data for Simulation Purposes. _Educational and Psychological Measurement_, _75_(4), 541–567. https://doi.org/10.1177/0013164414548894
- Rougier, N. P., Hinsen, K., Alexandre, F., Arildsen, T., Barba, L. A., Benureau, F. C., ... & Zito, T. (2017). Sustainable computational science: the ReScience initiative. _PeerJ Computer Science_, _3_, e142.
\section*{Acknowledgments}
We would like to thank and acknowledge the contribution of Dr. R. Philip Chalmers and Mark Christopher Adkins for providing a large portion of the replication code as well as support in using the SimDesign package (Chalmers, 2020).
\section*{Contributions}
Authors made the following contributions according to the CRediT framework <https://casrai.org/credit/>
Primary Replicator: Y. Andre Wang

-   Data Curation\
-   Formal Analysis (lead)\
-   Investigation\
-   Software\
-   Visualization (lead)\
-   Writing - Original Draft Preparation\
-   Writing - Review & Editing

Co-Pilot: Udi Alter

-   Formal Analysis (supporting)\
-   Investigation\
-   Software (supporting)\
-   Visualization (supporting)\
-   Validation\
-   Writing - Review & Editing






```{=tex}
\section*{References}
\begingroup
\hphantom{x}
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\FloatBarrier
\endgroup
\newpage
```
\\section\*{Appendix}

\\subsection\*{Additional result}

\subsection{Code organization}

The code and the files associated are organized in the form of a research compendium which can be found in the following git repository `https://github.com/replisims/Flora_Curran_2004`

```{r code_structure, cache = FALSE}
# which R packages and versions?
if ("fs" %in% installed.packages()) fs::dir_tree(path = ".", recurse = TRUE)
```

-   `foldername`: contains `<insert description>`
-   `filename`: contains `<insert description>`
-   ...

\\subsubsection\*{Reproducibility Information}

This report was last updated on `r Sys.time()`. The simulation replication was conducted using the following computational environment and dependencies:

\FloatBarrier


```{r colophon, cache = FALSE}
# which R packages and versions?
if ("devtools" %in% installed.packages()) devtools::session_info()
```

The current Git commit details are:

```{r git}
# what commit is this file at? 
if ("git2r" %in% installed.packages() & git2r::in_repository(path = ".")) git2r::repository(here::here())  
```
\\end{document}

%>%

